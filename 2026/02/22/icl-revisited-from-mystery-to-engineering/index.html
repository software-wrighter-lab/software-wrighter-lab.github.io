<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>In-Context Learning Revisited: From Mystery to Engineering | Software Wrighter Lab Blog</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="In-Context Learning Revisited: From Mystery to Engineering" />
<meta name="author" content="Software Wrighter" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="It was 2020 when GPT-3 shocked everyone. It could learn from examples in the query—without updating its weights. We called it In-Context Learning. But was it magic, or was it doing something deeper? Resource Link Video ICL Revisited Papers 4 References Phase 1: The Empirical Discovery (2020) The GPT-3 paper showed that large models could perform few-shot learning. Give them examples, and they generalize. No gradient updates. No retraining. Just forward passes. The surprising part was that scaling alone seemed to unlock it. Paper: Language Models are Few-Shot Learners ELI5: Show a big language model a few examples of a task in your prompt, and it figures out how to do the task—without any retraining. Nobody told it to do this. It just emerged when models got big enough. Main idea: Scale unlocks emergent capabilities. ICL was discovered, not designed. Phase 2: Mechanistic Explanations (2022) By 2022, researchers began probing the internal mechanisms. Several papers proposed that transformers implement implicit meta-learning. The model appears to learn during inference by performing gradient-descent-like operations internally. Paper: What Explains In-Context Learning in Transformers? ELI5: When you give a transformer examples, its attention layers do something that looks like fitting a simple linear model to those examples—on the fly, during the forward pass. It’s not memorizing; it’s computing a mini-solution. Main idea: ICL works because attention can simulate linear regression internally. Paper: Transformers Learn In-Context by Gradient Descent ELI5: The transformer’s forward pass is secretly doing something similar to training. The attention mechanism acts like one step of gradient descent over the examples you provided. Learning happens inside inference. Main idea: ICL is implicit gradient descent—learning hidden inside prediction. Phase 3: Engineering the Effect Once researchers understood that ordering and structure affect ICL, prompt design became less of an art and more of an optimization problem. The quality and arrangement of demonstrations directly shape performance. ICL became tunable. Researchers could now deliberately improve it rather than just observe it. Phase 4: Interactive ICL (2026) Recent work pushes this further. Models are trained to predict natural language critiques and feedback. If a model can predict what a teacher would say, it can internalize that signal. External correction becomes an internal capability. Paper: Improving Interactive In-Context Learning from Natural Language Feedback ELI5: Train a model to guess what feedback a human would give. Now the model has internalized the “teacher” and can improve itself without needing the actual teacher present. Self-correction without weight updates. Main idea: Models can learn to learn from feedback, making ICL interactive and self-improving. Beyond Language Newer work applies ICL to neuroscience discovery, showing that the mechanism is not limited to text tasks. It becomes a flexible reasoning substrate across domains. That’s when you know a concept has matured. The Arc Phase Era Key Insight Discovery 2020 Emerges from scale Explanation 2022 Implicit gradient descent Engineering 2023-24 Prompt design as optimization Self-improvement 2026 Learning from feedback The Deeper Insight In-Context Learning started as an emergent surprise. Now it’s becoming an engineered learning substrate inside transformers. It was not magic. It was meta-learning hiding in plain sight. References Paper Link Language Models are Few-Shot Learners (GPT-3) arXiv:2005.14165 What Explains In-Context Learning in Transformers? arXiv:2202.12837 Transformers Learn In-Context by Gradient Descent arXiv:2212.07677 Improving Interactive ICL from Natural Language Feedback arXiv:2602.16066 ICL started as “whoa, it works.” Now we understand “why it works.” Next: engineering it deliberately." />
<meta property="og:description" content="It was 2020 when GPT-3 shocked everyone. It could learn from examples in the query—without updating its weights. We called it In-Context Learning. But was it magic, or was it doing something deeper? Resource Link Video ICL Revisited Papers 4 References Phase 1: The Empirical Discovery (2020) The GPT-3 paper showed that large models could perform few-shot learning. Give them examples, and they generalize. No gradient updates. No retraining. Just forward passes. The surprising part was that scaling alone seemed to unlock it. Paper: Language Models are Few-Shot Learners ELI5: Show a big language model a few examples of a task in your prompt, and it figures out how to do the task—without any retraining. Nobody told it to do this. It just emerged when models got big enough. Main idea: Scale unlocks emergent capabilities. ICL was discovered, not designed. Phase 2: Mechanistic Explanations (2022) By 2022, researchers began probing the internal mechanisms. Several papers proposed that transformers implement implicit meta-learning. The model appears to learn during inference by performing gradient-descent-like operations internally. Paper: What Explains In-Context Learning in Transformers? ELI5: When you give a transformer examples, its attention layers do something that looks like fitting a simple linear model to those examples—on the fly, during the forward pass. It’s not memorizing; it’s computing a mini-solution. Main idea: ICL works because attention can simulate linear regression internally. Paper: Transformers Learn In-Context by Gradient Descent ELI5: The transformer’s forward pass is secretly doing something similar to training. The attention mechanism acts like one step of gradient descent over the examples you provided. Learning happens inside inference. Main idea: ICL is implicit gradient descent—learning hidden inside prediction. Phase 3: Engineering the Effect Once researchers understood that ordering and structure affect ICL, prompt design became less of an art and more of an optimization problem. The quality and arrangement of demonstrations directly shape performance. ICL became tunable. Researchers could now deliberately improve it rather than just observe it. Phase 4: Interactive ICL (2026) Recent work pushes this further. Models are trained to predict natural language critiques and feedback. If a model can predict what a teacher would say, it can internalize that signal. External correction becomes an internal capability. Paper: Improving Interactive In-Context Learning from Natural Language Feedback ELI5: Train a model to guess what feedback a human would give. Now the model has internalized the “teacher” and can improve itself without needing the actual teacher present. Self-correction without weight updates. Main idea: Models can learn to learn from feedback, making ICL interactive and self-improving. Beyond Language Newer work applies ICL to neuroscience discovery, showing that the mechanism is not limited to text tasks. It becomes a flexible reasoning substrate across domains. That’s when you know a concept has matured. The Arc Phase Era Key Insight Discovery 2020 Emerges from scale Explanation 2022 Implicit gradient descent Engineering 2023-24 Prompt design as optimization Self-improvement 2026 Learning from feedback The Deeper Insight In-Context Learning started as an emergent surprise. Now it’s becoming an engineered learning substrate inside transformers. It was not magic. It was meta-learning hiding in plain sight. References Paper Link Language Models are Few-Shot Learners (GPT-3) arXiv:2005.14165 What Explains In-Context Learning in Transformers? arXiv:2202.12837 Transformers Learn In-Context by Gradient Descent arXiv:2212.07677 Improving Interactive ICL from Natural Language Feedback arXiv:2602.16066 ICL started as “whoa, it works.” Now we understand “why it works.” Next: engineering it deliberately." />
<link rel="canonical" href="https://software-wrighter-lab.github.io/2026/02/22/icl-revisited-from-mystery-to-engineering/" />
<meta property="og:url" content="https://software-wrighter-lab.github.io/2026/02/22/icl-revisited-from-mystery-to-engineering/" />
<meta property="og:site_name" content="Software Wrighter Lab Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-02-22T00:00:00-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="In-Context Learning Revisited: From Mystery to Engineering" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Software Wrighter"},"dateModified":"2026-02-22T00:00:00-08:00","datePublished":"2026-02-22T00:00:00-08:00","description":"It was 2020 when GPT-3 shocked everyone. It could learn from examples in the query—without updating its weights. We called it In-Context Learning. But was it magic, or was it doing something deeper? Resource Link Video ICL Revisited Papers 4 References Phase 1: The Empirical Discovery (2020) The GPT-3 paper showed that large models could perform few-shot learning. Give them examples, and they generalize. No gradient updates. No retraining. Just forward passes. The surprising part was that scaling alone seemed to unlock it. Paper: Language Models are Few-Shot Learners ELI5: Show a big language model a few examples of a task in your prompt, and it figures out how to do the task—without any retraining. Nobody told it to do this. It just emerged when models got big enough. Main idea: Scale unlocks emergent capabilities. ICL was discovered, not designed. Phase 2: Mechanistic Explanations (2022) By 2022, researchers began probing the internal mechanisms. Several papers proposed that transformers implement implicit meta-learning. The model appears to learn during inference by performing gradient-descent-like operations internally. Paper: What Explains In-Context Learning in Transformers? ELI5: When you give a transformer examples, its attention layers do something that looks like fitting a simple linear model to those examples—on the fly, during the forward pass. It’s not memorizing; it’s computing a mini-solution. Main idea: ICL works because attention can simulate linear regression internally. Paper: Transformers Learn In-Context by Gradient Descent ELI5: The transformer’s forward pass is secretly doing something similar to training. The attention mechanism acts like one step of gradient descent over the examples you provided. Learning happens inside inference. Main idea: ICL is implicit gradient descent—learning hidden inside prediction. Phase 3: Engineering the Effect Once researchers understood that ordering and structure affect ICL, prompt design became less of an art and more of an optimization problem. The quality and arrangement of demonstrations directly shape performance. ICL became tunable. Researchers could now deliberately improve it rather than just observe it. Phase 4: Interactive ICL (2026) Recent work pushes this further. Models are trained to predict natural language critiques and feedback. If a model can predict what a teacher would say, it can internalize that signal. External correction becomes an internal capability. Paper: Improving Interactive In-Context Learning from Natural Language Feedback ELI5: Train a model to guess what feedback a human would give. Now the model has internalized the “teacher” and can improve itself without needing the actual teacher present. Self-correction without weight updates. Main idea: Models can learn to learn from feedback, making ICL interactive and self-improving. Beyond Language Newer work applies ICL to neuroscience discovery, showing that the mechanism is not limited to text tasks. It becomes a flexible reasoning substrate across domains. That’s when you know a concept has matured. The Arc Phase Era Key Insight Discovery 2020 Emerges from scale Explanation 2022 Implicit gradient descent Engineering 2023-24 Prompt design as optimization Self-improvement 2026 Learning from feedback The Deeper Insight In-Context Learning started as an emergent surprise. Now it’s becoming an engineered learning substrate inside transformers. It was not magic. It was meta-learning hiding in plain sight. References Paper Link Language Models are Few-Shot Learners (GPT-3) arXiv:2005.14165 What Explains In-Context Learning in Transformers? arXiv:2202.12837 Transformers Learn In-Context by Gradient Descent arXiv:2212.07677 Improving Interactive ICL from Natural Language Feedback arXiv:2602.16066 ICL started as “whoa, it works.” Now we understand “why it works.” Next: engineering it deliberately.","headline":"In-Context Learning Revisited: From Mystery to Engineering","mainEntityOfPage":{"@type":"WebPage","@id":"https://software-wrighter-lab.github.io/2026/02/22/icl-revisited-from-mystery-to-engineering/"},"url":"https://software-wrighter-lab.github.io/2026/02/22/icl-revisited-from-mystery-to-engineering/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://software-wrighter-lab.github.io/feed.xml" title="Software Wrighter Lab Blog" /><!-- Theme toggle script - load early to prevent flash -->
  <script>
    (function() {
      var stored = localStorage.getItem('sw-lab-theme');
      var theme = stored;
      if (!theme) {
        theme = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
      }
      document.documentElement.setAttribute('data-theme', theme);
    })();
  </script>
  <!-- Font size - load early to prevent flash -->
  <script>
    (function() {
      var NEW_DEFAULT = 110;
      var OLD_DEFAULT = 150;
      var stored = localStorage.getItem('sw-lab-font-size');
      var ack = localStorage.getItem('sw-lab-prefs-ack');
      var size = stored ? parseInt(stored, 10) : null;

      // Migration: if on old default and not acknowledged, use new default
      if (size === OLD_DEFAULT && ack !== 'true') {
        size = NEW_DEFAULT;
      } else if (size === null) {
        size = NEW_DEFAULT;
      }

      // Apply to post content when DOM is ready
      document.addEventListener('DOMContentLoaded', function() {
        var pc = document.querySelector('.post-content');
        if (pc) pc.style.fontSize = size + '%';
        var pl = document.querySelector('.post-list');
        if (pl) pl.style.fontSize = size + '%';
      });
    })();
  </script>
  <script src="/assets/js/theme-toggle.js" defer></script>
  <script src="/assets/js/font-size.js" defer></script>
  <script src="/assets/js/preferences.js" defer></script>
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">
      <img src="/assets/images/site/logo.jpg" alt="Software Wrighter Lab Blog" class="site-logo">
      <span class="site-title-text">Software Wrighter Lab Blog</span>
    </a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/abstracts/">Abstracts</a><a class="page-link" href="/index-all/">Index</a><a class="page-link" href="/series/">Series</a><a class="page-link" href="/tags/">Tags</a><a class="page-link" href="/categories/">Categories</a><a class="page-link" href="/search/">Search</a><div class="font-size-controls">
  <button class="font-size-btn" id="font-decrease" title="Decrease font size" aria-label="Decrease font size">A-</button>
  <button class="font-size-btn" id="font-reset" title="Reset font size" aria-label="Reset font size">A</button>
  <button class="font-size-btn" id="font-increase" title="Increase font size" aria-label="Increase font size">A+</button>
</div>
<button class="theme-toggle" aria-label="Switch theme" title="Switch theme">
  <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
  </svg>
  <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
    <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
  </svg>
</button>
</div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">In-Context Learning Revisited: From Mystery to Engineering</h1><p class="post-meta">February 22, 2026 &bull; Software Wrighter</p>
<p class="post-reading-info"><em><span class="post-word-count">643 words</span> &bull; <span class="post-read-time">4 min read</span></em> &bull; <span class="abstract-toggle" onclick="this.classList.toggle('open'); this.parentElement.nextElementSibling.classList.toggle('open')">Abstract</span></p><div class="post-meta-abstract">ICL evolved from emergent surprise (2020) to mechanistic understanding (2022) to engineered capability (2026). Transformers implement implicit gradient descent during inference---they learn without weight updates. The frontier: models learning from their own feedback. Not magic. Meta-learning in plain sight.</div><div class="post-taxonomies"><span class="post-categories"><a href="/categories/#machine-learning" class="category">machine-learning</a><a href="/categories/#llm" class="category">llm</a><a href="/categories/#research" class="category">research</a></span><span class="post-tags"><a href="/tags/#in-context-learning" class="tag">in-context-learning</a><a href="/tags/#icl" class="tag">icl</a><a href="/tags/#transformers" class="tag">transformers</a><a href="/tags/#meta-learning" class="tag">meta-learning</a><a href="/tags/#gpt" class="tag">gpt</a><a href="/tags/#few-shot-learning" class="tag">few-shot-learning</a></span></div></header><nav class="toc" data-toc-id="default">
  <h4>Contents</h4>
  <ul class="toc-list"></ul>
</nav>

<style>
/* Post content flows around floated TOC */
.post-content {
  overflow: hidden;
}

.toc {
  background: #fffde7;
  border-radius: 8px;
  padding: 1rem 1.5rem;
  margin: 0 1.5rem 1rem 0;
  float: left;
  max-width: 280px;
}

[data-theme="dark"] .toc {
  background: #3d3a00;
}

@media (prefers-color-scheme: dark) {
  :root:not([data-theme="light"]) .toc {
    background: #3d3a00;
  }
}

.toc h4 {
  margin: 0 0 0.75rem 0;
  font-size: 1rem;
}

.toc ul {
  margin: 0;
  padding-left: 1.25rem;
  list-style-type: disc;
}

.toc li {
  margin: 0.25rem 0;
}

.toc li.toc-h3 {
  margin-left: 1rem;
  font-size: 0.95em;
}

.toc a {
  text-decoration: none;
}

.toc a:hover {
  text-decoration: underline;
}


@media (max-width: 600px) {
  .toc {
    float: none;
    max-width: 100%;
    margin: 0 0 1.5rem 0;
  }
}

/* References section that floats alongside TOC */
.references-float {
  overflow: hidden; /* contain floated content */
}

.references-float h2 {
  margin-top: 0;
  font-size: 1.25rem;
}

.references-float table {
  font-size: 0.9em;
  width: 100%;
}

.references-float td, .references-float th {
  padding: 0.4rem 0.6rem;
  vertical-align: top;
}

.references-float td:first-child {
  white-space: nowrap;
  font-weight: bold;
  width: 1%;
}

@media (max-width: 600px) {
  .references-float table {
    font-size: 0.85em;
  }
}
</style>

<script>
(function() {
  // Run after DOM is ready
  function initTOC() {
    document.querySelectorAll('.toc').forEach(function(toc) {
      if (toc.dataset.initialized) return;
      toc.dataset.initialized = 'true';

      const tocList = toc.querySelector('.toc-list');
      if (!tocList) return;

      // Find the associated post-content (next sibling or parent's post-content)
      let article = toc.nextElementSibling;
      while (article && !article.classList.contains('post-content')) {
        article = article.nextElementSibling;
      }
      // Fallback: look for .post-content in the document (single post page)
      if (!article) {
        article = document.querySelector('.post-content');
      }

      if (!article) {
        toc.style.display = 'none';
        return;
      }

      const headings = article.querySelectorAll('h2, h3');

      if (headings.length < 3) {
        toc.style.display = 'none';
        return;
      }

      const tocId = toc.dataset.tocId || Math.random().toString(36).substr(2, 9);

      headings.forEach(function(heading, index) {
        // Add unique ID if missing
        if (!heading.id) {
          heading.id = 'toc-' + tocId + '-heading-' + index;
        }

        const li = document.createElement('li');
        li.className = 'toc-' + heading.tagName.toLowerCase();

        const a = document.createElement('a');
        a.href = '#' + heading.id;
        a.textContent = heading.textContent;

        li.appendChild(a);
        tocList.appendChild(li);
      });
    });
  }

  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', initTOC);
  } else {
    initTOC();
  }
})();
</script>
<div class="post-content e-content" itemprop="articleBody">
    <p><img src="/assets/images/posts/block-framework.png" class="post-marker" alt="" /></p>

<p>It was 2020 when GPT-3 shocked everyone. It could learn from examples in the query—without updating its weights. We called it In-Context Learning. But was it magic, or was it doing something deeper?</p>

<div class="resource-box">

  <table>
    <thead>
      <tr>
        <th>Resource</th>
        <th>Link</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Video</strong></td>
        <td><a href="https://www.youtube.com/shorts/zWKmRxChRlA">ICL Revisited</a><br /><a href="https://www.youtube.com/shorts/zWKmRxChRlA"><img src="https://img.youtube.com/vi/zWKmRxChRlA/mqdefault.jpg" alt="Video" class="video-thumb" /></a></td>
      </tr>
      <tr>
        <td><strong>Papers</strong></td>
        <td><a href="#references">4 References</a></td>
      </tr>
    </tbody>
  </table>

</div>

<h2 id="phase-1-the-empirical-discovery-2020">Phase 1: The Empirical Discovery (2020)</h2>

<p>The GPT-3 paper showed that large models could perform few-shot learning. Give them examples, and they generalize. No gradient updates. No retraining. Just forward passes.</p>

<p>The surprising part was that <strong>scaling alone</strong> seemed to unlock it.</p>

<h3 id="paper-language-models-are-few-shot-learners">Paper: Language Models are Few-Shot Learners</h3>

<p><strong>ELI5:</strong> Show a big language model a few examples of a task in your prompt, and it figures out how to do the task—without any retraining. Nobody told it to do this. It just emerged when models got big enough.</p>

<p><strong>Main idea:</strong> Scale unlocks emergent capabilities. ICL was discovered, not designed.</p>

<h2 id="phase-2-mechanistic-explanations-2022">Phase 2: Mechanistic Explanations (2022)</h2>

<p>By 2022, researchers began probing the internal mechanisms. Several papers proposed that transformers implement <strong>implicit meta-learning</strong>. The model appears to learn during inference by performing gradient-descent-like operations internally.</p>

<h3 id="paper-what-explains-in-context-learning-in-transformers">Paper: What Explains In-Context Learning in Transformers?</h3>

<p><strong>ELI5:</strong> When you give a transformer examples, its attention layers do something that looks like fitting a simple linear model to those examples—on the fly, during the forward pass. It’s not memorizing; it’s computing a mini-solution.</p>

<p><strong>Main idea:</strong> ICL works because attention can simulate linear regression internally.</p>

<h3 id="paper-transformers-learn-in-context-by-gradient-descent">Paper: Transformers Learn In-Context by Gradient Descent</h3>

<p><strong>ELI5:</strong> The transformer’s forward pass is secretly doing something similar to training. The attention mechanism acts like one step of gradient descent over the examples you provided. Learning happens inside inference.</p>

<p><strong>Main idea:</strong> ICL is implicit gradient descent—learning hidden inside prediction.</p>

<h2 id="phase-3-engineering-the-effect">Phase 3: Engineering the Effect</h2>

<p>Once researchers understood that ordering and structure affect ICL, prompt design became less of an art and more of an optimization problem. The quality and arrangement of demonstrations directly shape performance.</p>

<p>ICL became tunable. Researchers could now deliberately improve it rather than just observe it.</p>

<h2 id="phase-4-interactive-icl-2026">Phase 4: Interactive ICL (2026)</h2>

<p>Recent work pushes this further. Models are trained to predict natural language critiques and feedback. If a model can predict what a teacher would say, it can internalize that signal. External correction becomes an internal capability.</p>

<h3 id="paper-improving-interactive-in-context-learning-from-natural-language-feedback">Paper: Improving Interactive In-Context Learning from Natural Language Feedback</h3>

<p><strong>ELI5:</strong> Train a model to guess what feedback a human would give. Now the model has internalized the “teacher” and can improve itself without needing the actual teacher present. Self-correction without weight updates.</p>

<p><strong>Main idea:</strong> Models can learn to learn from feedback, making ICL interactive and self-improving.</p>

<h2 id="beyond-language">Beyond Language</h2>

<p>Newer work applies ICL to neuroscience discovery, showing that the mechanism is not limited to text tasks. It becomes a flexible reasoning substrate across domains. That’s when you know a concept has matured.</p>

<h2 id="the-arc">The Arc</h2>

<table>
  <thead>
    <tr>
      <th>Phase</th>
      <th>Era</th>
      <th>Key Insight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Discovery</strong></td>
      <td>2020</td>
      <td>Emerges from scale</td>
    </tr>
    <tr>
      <td><strong>Explanation</strong></td>
      <td>2022</td>
      <td>Implicit gradient descent</td>
    </tr>
    <tr>
      <td><strong>Engineering</strong></td>
      <td>2023-24</td>
      <td>Prompt design as optimization</td>
    </tr>
    <tr>
      <td><strong>Self-improvement</strong></td>
      <td>2026</td>
      <td>Learning from feedback</td>
    </tr>
  </tbody>
</table>

<h2 id="the-deeper-insight">The Deeper Insight</h2>

<p>In-Context Learning started as an emergent surprise. Now it’s becoming an engineered learning substrate inside transformers.</p>

<p>It was not magic. It was <strong>meta-learning hiding in plain sight</strong>.</p>

<div class="references-section">

  <h2 id="references">References</h2>

  <table>
    <thead>
      <tr>
        <th>Paper</th>
        <th>Link</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Language Models are Few-Shot Learners (GPT-3)</td>
        <td><a href="https://arxiv.org/abs/2005.14165">arXiv:2005.14165</a></td>
      </tr>
      <tr>
        <td>What Explains In-Context Learning in Transformers?</td>
        <td><a href="https://arxiv.org/abs/2202.12837">arXiv:2202.12837</a></td>
      </tr>
      <tr>
        <td>Transformers Learn In-Context by Gradient Descent</td>
        <td><a href="https://arxiv.org/abs/2212.07677">arXiv:2212.07677</a></td>
      </tr>
      <tr>
        <td>Improving Interactive ICL from Natural Language Feedback</td>
        <td><a href="https://arxiv.org/abs/2602.16066">arXiv:2602.16066</a></td>
      </tr>
    </tbody>
  </table>

</div>

<hr />

<p><em>ICL started as “whoa, it works.” Now we understand “why it works.” Next: engineering it deliberately.</em></p>


  </div><div class="series-nav">
    <p><em>Part 5 of the Machine Learning series. <a href="/series/#machine-learning">View all parts</a> | <a href="/2026/02/24/many-eyes-learning-part2-intrinsic-rewards/">Next: Part 6 →</a></em></p>
  </div>





<div class="youtube-embed-container" id="yt-container-zWKmRxChRlA">
  <h3>Watch the Video</h3>
  <div class="youtube-embed-wrapper">
    <iframe
      id="yt-player-zWKmRxChRlA"
      src="https://www.youtube.com/embed/zWKmRxChRlA?enablejsapi=1&mute=1&autoplay=1&cc_load_policy=1"
      title="YouTube video player"
      frameborder="0"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
      allowfullscreen
      loading="lazy">
    </iframe>
  </div>
  <p class="youtube-embed-note">Unmute to hear narration.</p>
</div>

<style>
.youtube-embed-container {
  margin: 2rem auto;
  padding: 1.5rem;
  background: var(--code-background-color, #f5f5f5);
  border-radius: 8px;
  width: 66%;
}

.youtube-embed-container h3 {
  margin-top: 0;
  margin-bottom: 1rem;
}

.youtube-embed-wrapper {
  position: relative;
  width: 100%;
  padding-bottom: 56.25%; /* 16:9 aspect ratio */
  height: 0;
  overflow: hidden;
}

.youtube-embed-wrapper iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border-radius: 4px;
}

.youtube-embed-note {
  margin-top: 0.75rem;
  margin-bottom: 0;
  font-size: 0.85rem;
  color: var(--text-muted-color, #666);
  font-style: italic;
}
</style>

<script>
(function() {
  const containerId = 'yt-container-zWKmRxChRlA';
  const playerId = 'yt-player-zWKmRxChRlA';

  // Load YouTube IFrame API if not already loaded
  if (!window.YT) {
    const tag = document.createElement('script');
    tag.src = 'https://www.youtube.com/iframe_api';
    const firstScriptTag = document.getElementsByTagName('script')[0];
    firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);
  }

  let player;
  let isPlaying = false;

  function onYouTubeIframeAPIReady() {
    player = new YT.Player(playerId, {
      events: {
        'onReady': onPlayerReady
      }
    });
  }

  function onPlayerReady(event) {
    setupIntersectionObserver();
  }

  function setupIntersectionObserver() {
    const container = document.getElementById(containerId);
    if (!container) return;

    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting && entry.intersectionRatio >= 0.5) {
          if (!isPlaying && player && player.playVideo) {
            player.playVideo();
            isPlaying = true;
          }
        } else {
          if (isPlaying && player && player.pauseVideo) {
            player.pauseVideo();
            isPlaying = false;
          }
        }
      });
    }, {
      threshold: [0.5]
    });

    observer.observe(container);
  }

  // Handle API ready callback
  if (window.YT && window.YT.Player) {
    onYouTubeIframeAPIReady();
  } else {
    window.onYouTubeIframeAPIReady = window.onYouTubeIframeAPIReady || onYouTubeIframeAPIReady;
    // Queue multiple players if needed
    const existingCallback = window.onYouTubeIframeAPIReady;
    window.onYouTubeIframeAPIReady = function() {
      if (existingCallback) existingCallback();
      onYouTubeIframeAPIReady();
    };
  }
})();
</script>

<img src="/assets/images/site/post-separator.png" class="post-separator" alt=""><a class="u-url" href="/2026/02/22/icl-revisited-from-mystery-to-engineering/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Software Wrighter Lab Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Mike Wright</li><li><a class="u-email" href="mailto:"></a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/softwarewrighter"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">softwarewrighter</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>AI coding agents, systems programming, and practical machine learning</p>
      </div>
    </div>

    <div class="footer-copyright">
      <p>Copyright &copy; 2026 Michael A. Wright</p>
    </div>

  </div>

  <button id="scroll-to-top" aria-label="Scroll to top" title="Scroll to top">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <polyline points="18 15 12 9 6 15"></polyline>
    </svg>
  </button>

  <style>
  #scroll-to-top {
    position: fixed;
    bottom: 2rem;
    right: 2rem;
    width: 44px;
    height: 44px;
    border-radius: 50%;
    border: none;
    background: var(--brand-color, #2a7ae2);
    color: white;
    cursor: pointer;
    opacity: 0;
    visibility: hidden;
    transition: opacity 0.3s, visibility 0.3s, transform 0.2s;
    z-index: 1000;
    display: flex;
    align-items: center;
    justify-content: center;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.2);
  }

  #scroll-to-top:hover {
    transform: scale(1.1);
  }

  #scroll-to-top.visible {
    opacity: 1;
    visibility: visible;
  }

  #scroll-to-top svg {
    width: 24px;
    height: 24px;
  }
  </style>

  <script>
  (function() {
    const btn = document.getElementById('scroll-to-top');
    if (!btn) return;

    window.addEventListener('scroll', function() {
      if (window.scrollY > 300) {
        btn.classList.add('visible');
      } else {
        btn.classList.remove('visible');
      }
    });

    btn.addEventListener('click', function() {
      window.scrollTo({ top: 0, behavior: 'smooth' });
    });
  })();
  </script>

</footer>
</body>

</html>
