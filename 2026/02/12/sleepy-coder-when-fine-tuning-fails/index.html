<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Towards Continuous LLM Learning (1): Sleepy Coder - When Fine-Tuning Fails | Software Wrighter Lab Blog</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Towards Continuous LLM Learning (1): Sleepy Coder - When Fine-Tuning Fails" />
<meta name="author" content="Software Wrighter" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="What if your AI coding assistant could learn from its mistakes? Not just for one session, but across training cycles. We built exactly that—and fifty-one adapters later, learned the mistake was trying to teach it at all. Resource Link Video Sleepy Coder Code sleepy-coder Share Paper arXiv:2602.06043 UWSH Paper arXiv:2512.05117 Part 2 Routing Prevents Forgetting The Dream: Day/Night Learning AI coding agents have a memory problem. They fix a bug today, then make the same mistake next week. Every session starts from the same frozen model. Nothing carries forward. The idea was elegant: build an agent that improves overnight. DAY CYCLE (Inference) Agent attempts to fix Rust compiler errors Successes and failures are logged ↓ NIGHT CYCLE (Training) Fine-tune on failure patterns using LoRA Create specialized adapters ↓ EVAL Test against benchmark Measure improvement ↓ (repeat) During the day, the agent works and we log its failures—the error messages, the broken code, and the fixes that worked. Overnight, we fine-tune the model on those failures. Each morning, a new checkpoint should wake up a little better than before. We based this on two papers from the Johns Hopkins team (Kaushik, Vaidya, Chaudhari, Chellappa, Yuille): Share LoRA Subspaces (arXiv:2602.06043) — Learn a shared low-rank basis across tasks, then train only coefficients (76x fewer parameters per task) UWSH (arXiv:2512.05117) — The Universal Weight Subspace Hypothesis suggests neural networks converge to shared spectral subspaces The theory was sound. The implementation worked. The results were devastating. The System The Sleepy Coder agent runs in a Rust runtime, fixing compiler errors on 30 “koans” (small coding exercises) across 5 error families: Borrow Checker: Ownership and lifetime errors Type Bounds: Missing trait implementations Result Handling: Option/Result conversions Type Mismatches: Incompatible types Missing Items: Undefined functions or modules The base model: Qwen2.5-Coder-1.5B-Instruct — small enough to train on a single GPU, capable enough to pass most koans without any fine-tuning. The Journey: From Hope to Reality Chapter 1: Naive LoRA First attempt: standard fine-tuning on failure patterns. Metric Before After Pass Rate 73.3% 60.0% Change — -13.3% Catastrophic forgetting. The model learned the new patterns but forgot how to do everything else. Chapter 2: The Paper Chase We found the Share paper promising “continual learning without forgetting.” The UWSH paper provided theoretical backing: neural networks naturally converge to shared low-rank subspaces. Key insight from Share: Train ONLY the coefficients. Keep the basis FROZEN. This meant ~21,000 trainable parameters instead of ~1.6 million. A 76x reduction. Chapter 3: The Proper Implementation SVD: Singular Value Decomposition breaks a matrix into components that reveal its underlying structure. In Share, SVD finds the common “directions” that multiple LoRA adapters share—a compressed basis that captures what they have in common. We rebuilt everything: Phase 1: Extract shared basis from 51 adapters via SVD Phase 2: Train only coefficient vectors (frozen basis) Phase 3: Merge and update basis periodically We trained 51 pattern-specific adapters. We followed the algorithm precisely. Chapter 4: The Stubborn Seven No matter what we tried, 7 tasks kept failing: Task The Problem bc_003 Mutable borrow while immutable exists bc_005 Double mutable borrow bc_010 Returning reference to local data tb_002 Missing Clone trait tb_007 Missing Hash trait tb_008 Missing Ord trait rh_004 Option to Result conversion These require deep understanding of Rust’s ownership system—something a 1.5B model can’t reliably learn. Chapter 5: The Final Score Approach Pass Rate vs Baseline Regressions Baseline (no training) 73.3% — 0 Naive LoRA 60.0% -13.3% Many Targeted LoRA (7 patterns) 63.3% -10% 4+ Replay buffer 70.0% -3.3% 2 Phase 2 coef-only (10K params) 66.7% -6.6% 2 Share Full (Ph2+Ph3) 73.3% 0% 0 The Share algorithm did exactly what it claimed: it prevented forgetting. But it couldn’t improve beyond baseline because there was nothing to improve. What Went Wrong 1. The Model Already Knows The base model already passes 73% of patterns. Training on these patterns doesn’t add knowledge—it dilutes what’s there. 2. Training Causes Forgetting Even training only on the 7 failure patterns (44 examples) caused 4 new regressions. The model’s knowledge is interconnected. 3. Averaging Destroys Specialization The Share paper assumes task routing at inference—selecting the right coefficients for each task. We averaged coefficients, which negated any specialization. 4. More Adapters Made It Worse Adapter Count Pass Rate 6 adapters 73.3% 51 adapters 70.0% More adapters meant more subspace dilution when averaging. The signal got lost in the noise. The Critical Insight LoRA fine-tuning cannot improve a capable base model for tasks it already handles reasonably well. The model’s knowledge is interconnected. Even 10,000 trainable parameters (0.0007% of the model) can break things. The baseline represents the ceiling, not the floor. What We Learned Read the room. If your base model passes 73%, maybe it doesn’t need fine-tuning. Maybe it needs better prompts. Negative results are results. 51 failed experiments taught us more than a successful one would have. Catastrophic forgetting is real. Small models especially can’t absorb new knowledge without losing old. Share prevents forgetting, not ignorance. The algorithm does what it claims—it just can’t create knowledge from nothing. Sometimes the answer is “don’t.” The best LoRA adapter for this task is no adapter. Task routing vs averaging matters. The Share paper assumes you select coefficients based on task type, not blend them together. AI coding agents cut corners. When implementing research papers, AI agents repeatedly stopped before completing all phases of the algorithm. I had to direct the agent to re-read the papers many times before it implemented them correctly. Paths Forward Since fine-tuning doesn’t work here, alternatives: Approach Tradeoff Prompt engineering No weight changes, limited by context Multi-turn repair Uses base model reasoning, slower Larger model (7B+) More capacity to absorb knowledge Task routing with Share Select coefficients, don’t average Model ensemble Multiple models, pick best output Accept baseline 73% may be good enough The Numbers Experiments run: 51 adapters, multiple algorithms Parameters trained: From 10K to 1.6M per adapter Best achieved: 73.3% (matches baseline) Target: ≥76.7% Conclusion: Target not achievable with LoRA Resources sleepy-coder Repository Share LoRA Subspaces Paper (arXiv:2602.06043) UWSH Paper (arXiv:2512.05117) Part 1 of the Towards Continuous LLM Learning series. View all parts Sometimes the most valuable research shows what doesn’t work. Fifty-one adapters later, we know: let sleeping models lie." />
<meta property="og:description" content="What if your AI coding assistant could learn from its mistakes? Not just for one session, but across training cycles. We built exactly that—and fifty-one adapters later, learned the mistake was trying to teach it at all. Resource Link Video Sleepy Coder Code sleepy-coder Share Paper arXiv:2602.06043 UWSH Paper arXiv:2512.05117 Part 2 Routing Prevents Forgetting The Dream: Day/Night Learning AI coding agents have a memory problem. They fix a bug today, then make the same mistake next week. Every session starts from the same frozen model. Nothing carries forward. The idea was elegant: build an agent that improves overnight. DAY CYCLE (Inference) Agent attempts to fix Rust compiler errors Successes and failures are logged ↓ NIGHT CYCLE (Training) Fine-tune on failure patterns using LoRA Create specialized adapters ↓ EVAL Test against benchmark Measure improvement ↓ (repeat) During the day, the agent works and we log its failures—the error messages, the broken code, and the fixes that worked. Overnight, we fine-tune the model on those failures. Each morning, a new checkpoint should wake up a little better than before. We based this on two papers from the Johns Hopkins team (Kaushik, Vaidya, Chaudhari, Chellappa, Yuille): Share LoRA Subspaces (arXiv:2602.06043) — Learn a shared low-rank basis across tasks, then train only coefficients (76x fewer parameters per task) UWSH (arXiv:2512.05117) — The Universal Weight Subspace Hypothesis suggests neural networks converge to shared spectral subspaces The theory was sound. The implementation worked. The results were devastating. The System The Sleepy Coder agent runs in a Rust runtime, fixing compiler errors on 30 “koans” (small coding exercises) across 5 error families: Borrow Checker: Ownership and lifetime errors Type Bounds: Missing trait implementations Result Handling: Option/Result conversions Type Mismatches: Incompatible types Missing Items: Undefined functions or modules The base model: Qwen2.5-Coder-1.5B-Instruct — small enough to train on a single GPU, capable enough to pass most koans without any fine-tuning. The Journey: From Hope to Reality Chapter 1: Naive LoRA First attempt: standard fine-tuning on failure patterns. Metric Before After Pass Rate 73.3% 60.0% Change — -13.3% Catastrophic forgetting. The model learned the new patterns but forgot how to do everything else. Chapter 2: The Paper Chase We found the Share paper promising “continual learning without forgetting.” The UWSH paper provided theoretical backing: neural networks naturally converge to shared low-rank subspaces. Key insight from Share: Train ONLY the coefficients. Keep the basis FROZEN. This meant ~21,000 trainable parameters instead of ~1.6 million. A 76x reduction. Chapter 3: The Proper Implementation SVD: Singular Value Decomposition breaks a matrix into components that reveal its underlying structure. In Share, SVD finds the common “directions” that multiple LoRA adapters share—a compressed basis that captures what they have in common. We rebuilt everything: Phase 1: Extract shared basis from 51 adapters via SVD Phase 2: Train only coefficient vectors (frozen basis) Phase 3: Merge and update basis periodically We trained 51 pattern-specific adapters. We followed the algorithm precisely. Chapter 4: The Stubborn Seven No matter what we tried, 7 tasks kept failing: Task The Problem bc_003 Mutable borrow while immutable exists bc_005 Double mutable borrow bc_010 Returning reference to local data tb_002 Missing Clone trait tb_007 Missing Hash trait tb_008 Missing Ord trait rh_004 Option to Result conversion These require deep understanding of Rust’s ownership system—something a 1.5B model can’t reliably learn. Chapter 5: The Final Score Approach Pass Rate vs Baseline Regressions Baseline (no training) 73.3% — 0 Naive LoRA 60.0% -13.3% Many Targeted LoRA (7 patterns) 63.3% -10% 4+ Replay buffer 70.0% -3.3% 2 Phase 2 coef-only (10K params) 66.7% -6.6% 2 Share Full (Ph2+Ph3) 73.3% 0% 0 The Share algorithm did exactly what it claimed: it prevented forgetting. But it couldn’t improve beyond baseline because there was nothing to improve. What Went Wrong 1. The Model Already Knows The base model already passes 73% of patterns. Training on these patterns doesn’t add knowledge—it dilutes what’s there. 2. Training Causes Forgetting Even training only on the 7 failure patterns (44 examples) caused 4 new regressions. The model’s knowledge is interconnected. 3. Averaging Destroys Specialization The Share paper assumes task routing at inference—selecting the right coefficients for each task. We averaged coefficients, which negated any specialization. 4. More Adapters Made It Worse Adapter Count Pass Rate 6 adapters 73.3% 51 adapters 70.0% More adapters meant more subspace dilution when averaging. The signal got lost in the noise. The Critical Insight LoRA fine-tuning cannot improve a capable base model for tasks it already handles reasonably well. The model’s knowledge is interconnected. Even 10,000 trainable parameters (0.0007% of the model) can break things. The baseline represents the ceiling, not the floor. What We Learned Read the room. If your base model passes 73%, maybe it doesn’t need fine-tuning. Maybe it needs better prompts. Negative results are results. 51 failed experiments taught us more than a successful one would have. Catastrophic forgetting is real. Small models especially can’t absorb new knowledge without losing old. Share prevents forgetting, not ignorance. The algorithm does what it claims—it just can’t create knowledge from nothing. Sometimes the answer is “don’t.” The best LoRA adapter for this task is no adapter. Task routing vs averaging matters. The Share paper assumes you select coefficients based on task type, not blend them together. AI coding agents cut corners. When implementing research papers, AI agents repeatedly stopped before completing all phases of the algorithm. I had to direct the agent to re-read the papers many times before it implemented them correctly. Paths Forward Since fine-tuning doesn’t work here, alternatives: Approach Tradeoff Prompt engineering No weight changes, limited by context Multi-turn repair Uses base model reasoning, slower Larger model (7B+) More capacity to absorb knowledge Task routing with Share Select coefficients, don’t average Model ensemble Multiple models, pick best output Accept baseline 73% may be good enough The Numbers Experiments run: 51 adapters, multiple algorithms Parameters trained: From 10K to 1.6M per adapter Best achieved: 73.3% (matches baseline) Target: ≥76.7% Conclusion: Target not achievable with LoRA Resources sleepy-coder Repository Share LoRA Subspaces Paper (arXiv:2602.06043) UWSH Paper (arXiv:2512.05117) Part 1 of the Towards Continuous LLM Learning series. View all parts Sometimes the most valuable research shows what doesn’t work. Fifty-one adapters later, we know: let sleeping models lie." />
<link rel="canonical" href="https://software-wrighter-lab.github.io/2026/02/12/sleepy-coder-when-fine-tuning-fails/" />
<meta property="og:url" content="https://software-wrighter-lab.github.io/2026/02/12/sleepy-coder-when-fine-tuning-fails/" />
<meta property="og:site_name" content="Software Wrighter Lab Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-02-12T00:30:00-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Towards Continuous LLM Learning (1): Sleepy Coder - When Fine-Tuning Fails" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Software Wrighter"},"dateModified":"2026-02-12T00:30:00-08:00","datePublished":"2026-02-12T00:30:00-08:00","description":"What if your AI coding assistant could learn from its mistakes? Not just for one session, but across training cycles. We built exactly that—and fifty-one adapters later, learned the mistake was trying to teach it at all. Resource Link Video Sleepy Coder Code sleepy-coder Share Paper arXiv:2602.06043 UWSH Paper arXiv:2512.05117 Part 2 Routing Prevents Forgetting The Dream: Day/Night Learning AI coding agents have a memory problem. They fix a bug today, then make the same mistake next week. Every session starts from the same frozen model. Nothing carries forward. The idea was elegant: build an agent that improves overnight. DAY CYCLE (Inference) Agent attempts to fix Rust compiler errors Successes and failures are logged ↓ NIGHT CYCLE (Training) Fine-tune on failure patterns using LoRA Create specialized adapters ↓ EVAL Test against benchmark Measure improvement ↓ (repeat) During the day, the agent works and we log its failures—the error messages, the broken code, and the fixes that worked. Overnight, we fine-tune the model on those failures. Each morning, a new checkpoint should wake up a little better than before. We based this on two papers from the Johns Hopkins team (Kaushik, Vaidya, Chaudhari, Chellappa, Yuille): Share LoRA Subspaces (arXiv:2602.06043) — Learn a shared low-rank basis across tasks, then train only coefficients (76x fewer parameters per task) UWSH (arXiv:2512.05117) — The Universal Weight Subspace Hypothesis suggests neural networks converge to shared spectral subspaces The theory was sound. The implementation worked. The results were devastating. The System The Sleepy Coder agent runs in a Rust runtime, fixing compiler errors on 30 “koans” (small coding exercises) across 5 error families: Borrow Checker: Ownership and lifetime errors Type Bounds: Missing trait implementations Result Handling: Option/Result conversions Type Mismatches: Incompatible types Missing Items: Undefined functions or modules The base model: Qwen2.5-Coder-1.5B-Instruct — small enough to train on a single GPU, capable enough to pass most koans without any fine-tuning. The Journey: From Hope to Reality Chapter 1: Naive LoRA First attempt: standard fine-tuning on failure patterns. Metric Before After Pass Rate 73.3% 60.0% Change — -13.3% Catastrophic forgetting. The model learned the new patterns but forgot how to do everything else. Chapter 2: The Paper Chase We found the Share paper promising “continual learning without forgetting.” The UWSH paper provided theoretical backing: neural networks naturally converge to shared low-rank subspaces. Key insight from Share: Train ONLY the coefficients. Keep the basis FROZEN. This meant ~21,000 trainable parameters instead of ~1.6 million. A 76x reduction. Chapter 3: The Proper Implementation SVD: Singular Value Decomposition breaks a matrix into components that reveal its underlying structure. In Share, SVD finds the common “directions” that multiple LoRA adapters share—a compressed basis that captures what they have in common. We rebuilt everything: Phase 1: Extract shared basis from 51 adapters via SVD Phase 2: Train only coefficient vectors (frozen basis) Phase 3: Merge and update basis periodically We trained 51 pattern-specific adapters. We followed the algorithm precisely. Chapter 4: The Stubborn Seven No matter what we tried, 7 tasks kept failing: Task The Problem bc_003 Mutable borrow while immutable exists bc_005 Double mutable borrow bc_010 Returning reference to local data tb_002 Missing Clone trait tb_007 Missing Hash trait tb_008 Missing Ord trait rh_004 Option to Result conversion These require deep understanding of Rust’s ownership system—something a 1.5B model can’t reliably learn. Chapter 5: The Final Score Approach Pass Rate vs Baseline Regressions Baseline (no training) 73.3% — 0 Naive LoRA 60.0% -13.3% Many Targeted LoRA (7 patterns) 63.3% -10% 4+ Replay buffer 70.0% -3.3% 2 Phase 2 coef-only (10K params) 66.7% -6.6% 2 Share Full (Ph2+Ph3) 73.3% 0% 0 The Share algorithm did exactly what it claimed: it prevented forgetting. But it couldn’t improve beyond baseline because there was nothing to improve. What Went Wrong 1. The Model Already Knows The base model already passes 73% of patterns. Training on these patterns doesn’t add knowledge—it dilutes what’s there. 2. Training Causes Forgetting Even training only on the 7 failure patterns (44 examples) caused 4 new regressions. The model’s knowledge is interconnected. 3. Averaging Destroys Specialization The Share paper assumes task routing at inference—selecting the right coefficients for each task. We averaged coefficients, which negated any specialization. 4. More Adapters Made It Worse Adapter Count Pass Rate 6 adapters 73.3% 51 adapters 70.0% More adapters meant more subspace dilution when averaging. The signal got lost in the noise. The Critical Insight LoRA fine-tuning cannot improve a capable base model for tasks it already handles reasonably well. The model’s knowledge is interconnected. Even 10,000 trainable parameters (0.0007% of the model) can break things. The baseline represents the ceiling, not the floor. What We Learned Read the room. If your base model passes 73%, maybe it doesn’t need fine-tuning. Maybe it needs better prompts. Negative results are results. 51 failed experiments taught us more than a successful one would have. Catastrophic forgetting is real. Small models especially can’t absorb new knowledge without losing old. Share prevents forgetting, not ignorance. The algorithm does what it claims—it just can’t create knowledge from nothing. Sometimes the answer is “don’t.” The best LoRA adapter for this task is no adapter. Task routing vs averaging matters. The Share paper assumes you select coefficients based on task type, not blend them together. AI coding agents cut corners. When implementing research papers, AI agents repeatedly stopped before completing all phases of the algorithm. I had to direct the agent to re-read the papers many times before it implemented them correctly. Paths Forward Since fine-tuning doesn’t work here, alternatives: Approach Tradeoff Prompt engineering No weight changes, limited by context Multi-turn repair Uses base model reasoning, slower Larger model (7B+) More capacity to absorb knowledge Task routing with Share Select coefficients, don’t average Model ensemble Multiple models, pick best output Accept baseline 73% may be good enough The Numbers Experiments run: 51 adapters, multiple algorithms Parameters trained: From 10K to 1.6M per adapter Best achieved: 73.3% (matches baseline) Target: ≥76.7% Conclusion: Target not achievable with LoRA Resources sleepy-coder Repository Share LoRA Subspaces Paper (arXiv:2602.06043) UWSH Paper (arXiv:2512.05117) Part 1 of the Towards Continuous LLM Learning series. View all parts Sometimes the most valuable research shows what doesn’t work. Fifty-one adapters later, we know: let sleeping models lie.","headline":"Towards Continuous LLM Learning (1): Sleepy Coder - When Fine-Tuning Fails","mainEntityOfPage":{"@type":"WebPage","@id":"https://software-wrighter-lab.github.io/2026/02/12/sleepy-coder-when-fine-tuning-fails/"},"url":"https://software-wrighter-lab.github.io/2026/02/12/sleepy-coder-when-fine-tuning-fails/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://software-wrighter-lab.github.io/feed.xml" title="Software Wrighter Lab Blog" /><!-- Theme toggle script - load early to prevent flash -->
  <script>
    (function() {
      var stored = localStorage.getItem('sw-lab-theme');
      var theme = stored;
      if (!theme) {
        theme = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
      }
      document.documentElement.setAttribute('data-theme', theme);
    })();
  </script>
  <!-- Font size - load early to prevent flash -->
  <script>
    (function() {
      var NEW_DEFAULT = 110;
      var OLD_DEFAULT = 150;
      var stored = localStorage.getItem('sw-lab-font-size');
      var ack = localStorage.getItem('sw-lab-prefs-ack');
      var size = stored ? parseInt(stored, 10) : null;

      // Migration: if on old default and not acknowledged, use new default
      if (size === OLD_DEFAULT && ack !== 'true') {
        size = NEW_DEFAULT;
      } else if (size === null) {
        size = NEW_DEFAULT;
      }

      // Apply to post content when DOM is ready
      document.addEventListener('DOMContentLoaded', function() {
        var pc = document.querySelector('.post-content');
        if (pc) pc.style.fontSize = size + '%';
        var pl = document.querySelector('.post-list');
        if (pl) pl.style.fontSize = size + '%';
      });
    })();
  </script>
  <script src="/assets/js/theme-toggle.js" defer></script>
  <script src="/assets/js/font-size.js" defer></script>
  <script src="/assets/js/preferences.js" defer></script>
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">
      <img src="/assets/images/site/logo.jpg" alt="Software Wrighter Lab Blog" class="site-logo">
      <span class="site-title-text">Software Wrighter Lab Blog</span>
    </a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/abstracts/">Abstracts</a><a class="page-link" href="/index-all/">Index</a><a class="page-link" href="/series/">Series</a><a class="page-link" href="/tags/">Tags</a><a class="page-link" href="/categories/">Categories</a><a class="page-link" href="/search/">Search</a><div class="font-size-controls">
  <button class="font-size-btn" id="font-decrease" title="Decrease font size" aria-label="Decrease font size">A-</button>
  <button class="font-size-btn" id="font-reset" title="Reset font size" aria-label="Reset font size">A</button>
  <button class="font-size-btn" id="font-increase" title="Increase font size" aria-label="Increase font size">A+</button>
</div>
<button class="theme-toggle" aria-label="Switch theme" title="Switch theme">
  <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
  </svg>
  <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
    <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
  </svg>
</button>
</div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Towards Continuous LLM Learning (1): Sleepy Coder - When Fine-Tuning Fails</h1><p class="post-meta">February 12, 2026 &bull; Software Wrighter</p>
<p class="post-reading-info"><em><span class="post-word-count">1224 words</span> &bull; <span class="post-read-time">7 min read</span></em> &bull; <span class="abstract-toggle" onclick="this.classList.toggle('open'); this.parentElement.nextElementSibling.classList.toggle('open')">Abstract</span></p><div class="post-meta-abstract">What happens when you fine-tune a model on new tasks? It forgets old ones. This post documents our implementation of the Share algorithm in Rust—using SVD-based subspace extraction to enable continual learning without catastrophic forgetting. Part 1 covers the problem and initial negative results.</div><div class="post-taxonomies"><span class="post-categories"><a href="/categories/#llm" class="category">llm</a><a href="/categories/#machine-learning" class="category">machine-learning</a><a href="/categories/#research" class="category">research</a></span><span class="post-tags"><a href="/tags/#lora" class="tag">lora</a><a href="/tags/#fine-tuning" class="tag">fine-tuning</a><a href="/tags/#continual-learning" class="tag">continual-learning</a><a href="/tags/#rust" class="tag">rust</a><a href="/tags/#catastrophic-forgetting" class="tag">catastrophic-forgetting</a></span></div></header><nav class="toc" data-toc-id="default">
  <h4>Contents</h4>
  <ul class="toc-list"></ul>
</nav>

<style>
/* Post content flows around floated TOC */
.post-content {
  overflow: hidden;
}

.toc {
  background: #fffde7;
  border-radius: 8px;
  padding: 1rem 1.5rem;
  margin: 0 1.5rem 1rem 0;
  float: left;
  max-width: 280px;
}

[data-theme="dark"] .toc {
  background: #3d3a00;
}

@media (prefers-color-scheme: dark) {
  :root:not([data-theme="light"]) .toc {
    background: #3d3a00;
  }
}

.toc h4 {
  margin: 0 0 0.75rem 0;
  font-size: 1rem;
}

.toc ul {
  margin: 0;
  padding-left: 1.25rem;
  list-style-type: disc;
}

.toc li {
  margin: 0.25rem 0;
}

.toc li.toc-h3 {
  margin-left: 1rem;
  font-size: 0.95em;
}

.toc a {
  text-decoration: none;
}

.toc a:hover {
  text-decoration: underline;
}


@media (max-width: 600px) {
  .toc {
    float: none;
    max-width: 100%;
    margin: 0 0 1.5rem 0;
  }
}

/* References section that floats alongside TOC */
.references-float {
  overflow: hidden; /* contain floated content */
}

.references-float h2 {
  margin-top: 0;
  font-size: 1.25rem;
}

.references-float table {
  font-size: 0.9em;
  width: 100%;
}

.references-float td, .references-float th {
  padding: 0.4rem 0.6rem;
  vertical-align: top;
}

.references-float td:first-child {
  white-space: nowrap;
  font-weight: bold;
  width: 1%;
}

@media (max-width: 600px) {
  .references-float table {
    font-size: 0.85em;
  }
}
</style>

<script>
(function() {
  // Run after DOM is ready
  function initTOC() {
    document.querySelectorAll('.toc').forEach(function(toc) {
      if (toc.dataset.initialized) return;
      toc.dataset.initialized = 'true';

      const tocList = toc.querySelector('.toc-list');
      if (!tocList) return;

      // Find the associated post-content (next sibling or parent's post-content)
      let article = toc.nextElementSibling;
      while (article && !article.classList.contains('post-content')) {
        article = article.nextElementSibling;
      }
      // Fallback: look for .post-content in the document (single post page)
      if (!article) {
        article = document.querySelector('.post-content');
      }

      if (!article) {
        toc.style.display = 'none';
        return;
      }

      const headings = article.querySelectorAll('h2, h3');

      if (headings.length < 3) {
        toc.style.display = 'none';
        return;
      }

      const tocId = toc.dataset.tocId || Math.random().toString(36).substr(2, 9);

      headings.forEach(function(heading, index) {
        // Add unique ID if missing
        if (!heading.id) {
          heading.id = 'toc-' + tocId + '-heading-' + index;
        }

        const li = document.createElement('li');
        li.className = 'toc-' + heading.tagName.toLowerCase();

        const a = document.createElement('a');
        a.href = '#' + heading.id;
        a.textContent = heading.textContent;

        li.appendChild(a);
        tocList.appendChild(li);
      });
    });
  }

  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', initTOC);
  } else {
    initTOC();
  }
})();
</script>
<div class="post-content e-content" itemprop="articleBody">
    <p><img src="/assets/images/posts/sleeper-dreaming.png" class="post-marker" alt="" /></p>

<p>What if your AI coding assistant could learn from its mistakes? Not just for one session, but across training cycles. We built exactly that—and fifty-one adapters later, learned the mistake was trying to teach it at all.</p>

<div class="resource-box">

  <table>
    <thead>
      <tr>
        <th>Resource</th>
        <th>Link</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Video</strong></td>
        <td><a href="https://youtu.be/YhAbOvWEkzE">Sleepy Coder</a><br /><a href="https://youtu.be/YhAbOvWEkzE"><img src="https://img.youtube.com/vi/YhAbOvWEkzE/mqdefault.jpg" alt="Video" class="video-thumb" /></a></td>
      </tr>
      <tr>
        <td><strong>Code</strong></td>
        <td><a href="https://github.com/softwarewrighter/sleepy-coder">sleepy-coder</a></td>
      </tr>
      <tr>
        <td><strong>Share Paper</strong></td>
        <td><a href="https://arxiv.org/abs/2602.06043">arXiv:2602.06043</a></td>
      </tr>
      <tr>
        <td><strong>UWSH Paper</strong></td>
        <td><a href="https://arxiv.org/abs/2512.05117">arXiv:2512.05117</a></td>
      </tr>
      <tr>
        <td><strong>Part 2</strong></td>
        <td><a href="/2026/02/18/sleepy-coder-routing-prevents-forgetting/">Routing Prevents Forgetting</a></td>
      </tr>
    </tbody>
  </table>

</div>

<h2 id="the-dream-daynight-learning">The Dream: Day/Night Learning</h2>

<p>AI coding agents have a memory problem. They fix a bug today, then make the same mistake next week. Every session starts from the same frozen model. Nothing carries forward.</p>

<p>The idea was elegant: build an agent that improves overnight.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DAY CYCLE (Inference)
  Agent attempts to fix Rust compiler errors
  Successes and failures are logged
        ↓
NIGHT CYCLE (Training)
  Fine-tune on failure patterns using LoRA
  Create specialized adapters
        ↓
EVAL
  Test against benchmark
  Measure improvement
        ↓
(repeat)
</code></pre></div></div>

<p>During the day, the agent works and we log its failures—the error messages, the broken code, and the fixes that worked. Overnight, we fine-tune the model on those failures. Each morning, a new checkpoint should wake up a little better than before.</p>

<p>We based this on two papers from the Johns Hopkins team (Kaushik, Vaidya, Chaudhari, Chellappa, Yuille):</p>

<ol>
  <li>
    <p><strong>Share LoRA Subspaces</strong> (arXiv:2602.06043) — Learn a shared low-rank basis across tasks, then train only coefficients (76x fewer parameters per task)</p>
  </li>
  <li>
    <p><strong>UWSH</strong> (arXiv:2512.05117) — The Universal Weight Subspace Hypothesis suggests neural networks converge to shared spectral subspaces</p>
  </li>
</ol>

<p>The theory was sound. The implementation worked. The results were devastating.</p>

<h2 id="the-system">The System</h2>

<p>The Sleepy Coder agent runs in a Rust runtime, fixing compiler errors on 30 “koans” (small coding exercises) across 5 error families:</p>

<ul>
  <li><strong>Borrow Checker</strong>: Ownership and lifetime errors</li>
  <li><strong>Type Bounds</strong>: Missing trait implementations</li>
  <li><strong>Result Handling</strong>: Option/Result conversions</li>
  <li><strong>Type Mismatches</strong>: Incompatible types</li>
  <li><strong>Missing Items</strong>: Undefined functions or modules</li>
</ul>

<p>The base model: <strong>Qwen2.5-Coder-1.5B-Instruct</strong> — small enough to train on a single GPU, capable enough to pass most koans without any fine-tuning.</p>

<h2 id="the-journey-from-hope-to-reality">The Journey: From Hope to Reality</h2>

<h3 id="chapter-1-naive-lora">Chapter 1: Naive LoRA</h3>

<p>First attempt: standard fine-tuning on failure patterns.</p>

<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Before</th>
      <th>After</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pass Rate</td>
      <td>73.3%</td>
      <td>60.0%</td>
    </tr>
    <tr>
      <td>Change</td>
      <td>—</td>
      <td>-13.3%</td>
    </tr>
  </tbody>
</table>

<p>Catastrophic forgetting. The model learned the new patterns but forgot how to do everything else.</p>

<h3 id="chapter-2-the-paper-chase">Chapter 2: The Paper Chase</h3>

<p>We found the Share paper promising “continual learning without forgetting.” The UWSH paper provided theoretical backing: neural networks naturally converge to shared low-rank subspaces.</p>

<p>Key insight from Share:</p>
<blockquote>
  <p>Train ONLY the coefficients. Keep the basis FROZEN.</p>
</blockquote>

<p>This meant ~21,000 trainable parameters instead of ~1.6 million. A 76x reduction.</p>

<h3 id="chapter-3-the-proper-implementation">Chapter 3: The Proper Implementation</h3>

<div class="definition-box">
  <p><strong>SVD: Singular Value Decomposition</strong> breaks a matrix into components that reveal its underlying structure. In Share, SVD finds the common “directions” that multiple LoRA adapters share—a compressed basis that captures what they have in common.</p>
</div>

<p>We rebuilt everything:</p>

<ul>
  <li><strong>Phase 1:</strong> Extract shared basis from 51 adapters via SVD</li>
  <li><strong>Phase 2:</strong> Train only coefficient vectors (frozen basis)</li>
  <li><strong>Phase 3:</strong> Merge and update basis periodically</li>
</ul>

<p>We trained 51 pattern-specific adapters. We followed the algorithm precisely.</p>

<h3 id="chapter-4-the-stubborn-seven">Chapter 4: The Stubborn Seven</h3>

<p>No matter what we tried, 7 tasks kept failing:</p>

<table>
  <thead>
    <tr>
      <th>Task</th>
      <th>The Problem</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>bc_003</td>
      <td>Mutable borrow while immutable exists</td>
    </tr>
    <tr>
      <td>bc_005</td>
      <td>Double mutable borrow</td>
    </tr>
    <tr>
      <td>bc_010</td>
      <td>Returning reference to local data</td>
    </tr>
    <tr>
      <td>tb_002</td>
      <td>Missing Clone trait</td>
    </tr>
    <tr>
      <td>tb_007</td>
      <td>Missing Hash trait</td>
    </tr>
    <tr>
      <td>tb_008</td>
      <td>Missing Ord trait</td>
    </tr>
    <tr>
      <td>rh_004</td>
      <td>Option to Result conversion</td>
    </tr>
  </tbody>
</table>

<p>These require deep understanding of Rust’s ownership system—something a 1.5B model can’t reliably learn.</p>

<h3 id="chapter-5-the-final-score">Chapter 5: The Final Score</h3>

<table>
  <thead>
    <tr>
      <th>Approach</th>
      <th>Pass Rate</th>
      <th>vs Baseline</th>
      <th>Regressions</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Baseline (no training)</td>
      <td>73.3%</td>
      <td>—</td>
      <td>0</td>
    </tr>
    <tr>
      <td>Naive LoRA</td>
      <td>60.0%</td>
      <td>-13.3%</td>
      <td>Many</td>
    </tr>
    <tr>
      <td>Targeted LoRA (7 patterns)</td>
      <td>63.3%</td>
      <td>-10%</td>
      <td>4+</td>
    </tr>
    <tr>
      <td>Replay buffer</td>
      <td>70.0%</td>
      <td>-3.3%</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Phase 2 coef-only (10K params)</td>
      <td>66.7%</td>
      <td>-6.6%</td>
      <td>2</td>
    </tr>
    <tr>
      <td><strong>Share Full (Ph2+Ph3)</strong></td>
      <td><strong>73.3%</strong></td>
      <td><strong>0%</strong></td>
      <td><strong>0</strong></td>
    </tr>
  </tbody>
</table>

<p>The Share algorithm did exactly what it claimed: it prevented forgetting. But it couldn’t improve beyond baseline because <strong>there was nothing to improve.</strong></p>

<h2 id="what-went-wrong">What Went Wrong</h2>

<h3 id="1-the-model-already-knows">1. The Model Already Knows</h3>

<p>The base model already passes 73% of patterns. Training on these patterns doesn’t add knowledge—it dilutes what’s there.</p>

<h3 id="2-training-causes-forgetting">2. Training Causes Forgetting</h3>

<p>Even training only on the 7 failure patterns (44 examples) caused 4 new regressions. The model’s knowledge is interconnected.</p>

<h3 id="3-averaging-destroys-specialization">3. Averaging Destroys Specialization</h3>

<p>The Share paper assumes task routing at inference—selecting the right coefficients for each task. We averaged coefficients, which negated any specialization.</p>

<h3 id="4-more-adapters-made-it-worse">4. More Adapters Made It Worse</h3>

<table>
  <thead>
    <tr>
      <th>Adapter Count</th>
      <th>Pass Rate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>6 adapters</td>
      <td>73.3%</td>
    </tr>
    <tr>
      <td>51 adapters</td>
      <td>70.0%</td>
    </tr>
  </tbody>
</table>

<p>More adapters meant more subspace dilution when averaging. The signal got lost in the noise.</p>

<h2 id="the-critical-insight">The Critical Insight</h2>

<p><strong>LoRA fine-tuning cannot improve a capable base model for tasks it already handles reasonably well.</strong></p>

<p>The model’s knowledge is interconnected. Even 10,000 trainable parameters (0.0007% of the model) can break things. The baseline represents the ceiling, not the floor.</p>

<h2 id="what-we-learned">What We Learned</h2>

<ol>
  <li>
    <p><strong>Read the room.</strong> If your base model passes 73%, maybe it doesn’t need fine-tuning. Maybe it needs better prompts.</p>
  </li>
  <li>
    <p><strong>Negative results are results.</strong> 51 failed experiments taught us more than a successful one would have.</p>
  </li>
  <li>
    <p><strong>Catastrophic forgetting is real.</strong> Small models especially can’t absorb new knowledge without losing old.</p>
  </li>
  <li>
    <p><strong>Share prevents forgetting, not ignorance.</strong> The algorithm does what it claims—it just can’t create knowledge from nothing.</p>
  </li>
  <li>
    <p><strong>Sometimes the answer is “don’t.”</strong> The best LoRA adapter for this task is no adapter.</p>
  </li>
  <li>
    <p><strong>Task routing vs averaging matters.</strong> The Share paper assumes you select coefficients based on task type, not blend them together.</p>
  </li>
  <li>
    <p><strong>AI coding agents cut corners.</strong> When implementing research papers, AI agents repeatedly stopped before completing all phases of the algorithm. I had to direct the agent to re-read the papers many times before it implemented them correctly.</p>
  </li>
</ol>

<h2 id="paths-forward">Paths Forward</h2>

<p>Since fine-tuning doesn’t work here, alternatives:</p>

<table>
  <thead>
    <tr>
      <th>Approach</th>
      <th>Tradeoff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Prompt engineering</td>
      <td>No weight changes, limited by context</td>
    </tr>
    <tr>
      <td>Multi-turn repair</td>
      <td>Uses base model reasoning, slower</td>
    </tr>
    <tr>
      <td>Larger model (7B+)</td>
      <td>More capacity to absorb knowledge</td>
    </tr>
    <tr>
      <td>Task routing with Share</td>
      <td>Select coefficients, don’t average</td>
    </tr>
    <tr>
      <td>Model ensemble</td>
      <td>Multiple models, pick best output</td>
    </tr>
    <tr>
      <td>Accept baseline</td>
      <td>73% may be good enough</td>
    </tr>
  </tbody>
</table>

<h2 id="the-numbers">The Numbers</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Experiments run:        51 adapters, multiple algorithms
Parameters trained:     From 10K to 1.6M per adapter
Best achieved:          73.3% (matches baseline)
Target:                 ≥76.7%
Conclusion:             Target not achievable with LoRA
</code></pre></div></div>

<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://github.com/softwarewrighter/sleepy-coder">sleepy-coder Repository</a></li>
  <li><a href="https://arxiv.org/abs/2602.06043">Share LoRA Subspaces Paper (arXiv:2602.06043)</a></li>
  <li><a href="https://arxiv.org/abs/2512.05117">UWSH Paper (arXiv:2512.05117)</a></li>
</ul>

<hr />

<p><em>Part 1 of the Towards Continuous LLM Learning series. <a href="/series/#towards-continuous-llm-learning">View all parts</a></em></p>

<p><em>Sometimes the most valuable research shows what doesn’t work. Fifty-one adapters later, we know: let sleeping models lie.</em></p>


  </div>





<div class="youtube-embed-container" id="yt-container-YhAbOvWEkzE">
  <h3>Watch the Video</h3>
  <div class="youtube-embed-wrapper">
    <iframe
      id="yt-player-YhAbOvWEkzE"
      src="https://www.youtube.com/embed/YhAbOvWEkzE?enablejsapi=1&mute=1&autoplay=1&cc_load_policy=1"
      title="YouTube video player"
      frameborder="0"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
      allowfullscreen
      loading="lazy">
    </iframe>
  </div>
  <p class="youtube-embed-note">Unmute to hear narration.</p>
</div>

<style>
.youtube-embed-container {
  margin: 2rem auto;
  padding: 1.5rem;
  background: var(--code-background-color, #f5f5f5);
  border-radius: 8px;
  width: 66%;
}

.youtube-embed-container h3 {
  margin-top: 0;
  margin-bottom: 1rem;
}

.youtube-embed-wrapper {
  position: relative;
  width: 100%;
  padding-bottom: 56.25%; /* 16:9 aspect ratio */
  height: 0;
  overflow: hidden;
}

.youtube-embed-wrapper iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border-radius: 4px;
}

.youtube-embed-note {
  margin-top: 0.75rem;
  margin-bottom: 0;
  font-size: 0.85rem;
  color: var(--text-muted-color, #666);
  font-style: italic;
}
</style>

<script>
(function() {
  const containerId = 'yt-container-YhAbOvWEkzE';
  const playerId = 'yt-player-YhAbOvWEkzE';

  // Load YouTube IFrame API if not already loaded
  if (!window.YT) {
    const tag = document.createElement('script');
    tag.src = 'https://www.youtube.com/iframe_api';
    const firstScriptTag = document.getElementsByTagName('script')[0];
    firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);
  }

  let player;
  let isPlaying = false;

  function onYouTubeIframeAPIReady() {
    player = new YT.Player(playerId, {
      events: {
        'onReady': onPlayerReady
      }
    });
  }

  function onPlayerReady(event) {
    setupIntersectionObserver();
  }

  function setupIntersectionObserver() {
    const container = document.getElementById(containerId);
    if (!container) return;

    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting && entry.intersectionRatio >= 0.5) {
          if (!isPlaying && player && player.playVideo) {
            player.playVideo();
            isPlaying = true;
          }
        } else {
          if (isPlaying && player && player.pauseVideo) {
            player.pauseVideo();
            isPlaying = false;
          }
        }
      });
    }, {
      threshold: [0.5]
    });

    observer.observe(container);
  }

  // Handle API ready callback
  if (window.YT && window.YT.Player) {
    onYouTubeIframeAPIReady();
  } else {
    window.onYouTubeIframeAPIReady = window.onYouTubeIframeAPIReady || onYouTubeIframeAPIReady;
    // Queue multiple players if needed
    const existingCallback = window.onYouTubeIframeAPIReady;
    window.onYouTubeIframeAPIReady = function() {
      if (existingCallback) existingCallback();
      onYouTubeIframeAPIReady();
    };
  }
})();
</script>

<img src="/assets/images/site/post-separator.png" class="post-separator" alt=""><a class="u-url" href="/2026/02/12/sleepy-coder-when-fine-tuning-fails/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Software Wrighter Lab Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Mike Wright</li><li><a class="u-email" href="mailto:"></a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/softwarewrighter"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">softwarewrighter</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>AI coding agents, systems programming, and practical machine learning</p>
      </div>
    </div>

    <div class="footer-copyright">
      <p>Copyright &copy; 2026 Michael A. Wright</p>
    </div>

  </div>

  <button id="scroll-to-top" aria-label="Scroll to top" title="Scroll to top">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <polyline points="18 15 12 9 6 15"></polyline>
    </svg>
  </button>

  <style>
  #scroll-to-top {
    position: fixed;
    bottom: 2rem;
    right: 2rem;
    width: 44px;
    height: 44px;
    border-radius: 50%;
    border: none;
    background: var(--brand-color, #2a7ae2);
    color: white;
    cursor: pointer;
    opacity: 0;
    visibility: hidden;
    transition: opacity 0.3s, visibility 0.3s, transform 0.2s;
    z-index: 1000;
    display: flex;
    align-items: center;
    justify-content: center;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.2);
  }

  #scroll-to-top:hover {
    transform: scale(1.1);
  }

  #scroll-to-top.visible {
    opacity: 1;
    visibility: visible;
  }

  #scroll-to-top svg {
    width: 24px;
    height: 24px;
  }
  </style>

  <script>
  (function() {
    const btn = document.getElementById('scroll-to-top');
    if (!btn) return;

    window.addEventListener('scroll', function() {
      if (window.scrollY > 300) {
        btn.classList.add('visible');
      } else {
        btn.classList.remove('visible');
      }
    });

    btn.addEventListener('click', function() {
      window.scrollTo({ top: 0, behavior: 'smooth' });
    });
  })();
  </script>

</footer>
</body>

</html>
