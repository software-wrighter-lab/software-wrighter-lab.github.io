<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How AI Learns Part 1: The Many Meanings of Learning | Software Wrighter Lab Blog</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="How AI Learns Part 1: The Many Meanings of Learning" />
<meta name="author" content="Software Wrighter" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="When people say, “AI learned something,” they usually mean one of at least four very different things. Large Language Models (LLMs) do not learn in one single way. They learn at different time scales, in different locations, and with very different consequences. To understand modern AI systems—especially agents—we need to separate these layers. Resource Link Related ICL Revisited | RLM | Engram Four Time Scales of Learning Learning happens at different layers with different persistence and speed. 1. Pretraining (Years) This is the foundation. The model trains on massive datasets using gradient descent. The result is a set of weights—billions of parameters—encoding statistical structure of language and knowledge. This learning: Is slow and expensive Persists across restarts Cannot easily be reversed Is vulnerable to interference if modified later Think of this as long-term biological memory. 2. Fine-Tuning (Days to Weeks) Fine-tuning modifies the weights further, but with narrower data. This includes: Instruction tuning (following directions) Alignment methods (Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO)) Domain adaptation Parameter-efficient methods like Low-Rank Adaptation (LoRA) This is still weight-based learning. It persists across restarts. It risks catastrophic forgetting. It modifies the brain itself. 3. Memory-Based Learning (Seconds to Minutes) This is where many modern systems shift. Instead of changing weights, they store information externally: RAG (Retrieval-Augmented Generation) CAG (Cache-Augmented Generation) Vector databases Engram-style memory modules The model retrieves relevant memory per query. The brain stays stable. The notebook grows. This learning: Persists across restarts Survives model upgrades Does not cause forgetting Is fast 4. In-Context Learning (Milliseconds) This is temporary reasoning scaffolding. Information exists only in the prompt window. It: Does not update weights Does not persist across sessions Is powerful but fragile Suffers from context rot This is working memory. Why This Matters Most discussions collapse all of this into “the model learned.” But: Updating weights risks forgetting Updating memory does not Updating prompts does not persist Updating adapters can be modular and reversible Continuous learning systems must coordinate all four. Persistence Comparison Mechanism Persists Across Chat? Persists Across Restart? Persists Across Model Change? Pretraining Yes Yes No Fine-tune Yes Yes No LoRA Yes Yes Usually Distillation Yes Yes No ICL No No No RAG Yes Yes Yes Engram Yes Yes Yes CAG Yes Yes Yes That last column is subtle but powerful for agents. References Concept Paper LoRA LoRA: Low-Rank Adaptation of Large Language Models (Hu et al. 2021) RAG Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (Lewis et al. 2020) ICL What Can Transformers Learn In-Context? (Garg et al. 2022) Engram Engram: Conditional Memory via Scalable Lookup (DeepSeek 2025) DPO Direct Preference Optimization (Rafailov et al. 2023) Coming Next In Part 2, we’ll examine the two fundamental failure modes that arise from confusing these layers: catastrophic forgetting and context rot. Learning happens in layers of permanence." />
<meta property="og:description" content="When people say, “AI learned something,” they usually mean one of at least four very different things. Large Language Models (LLMs) do not learn in one single way. They learn at different time scales, in different locations, and with very different consequences. To understand modern AI systems—especially agents—we need to separate these layers. Resource Link Related ICL Revisited | RLM | Engram Four Time Scales of Learning Learning happens at different layers with different persistence and speed. 1. Pretraining (Years) This is the foundation. The model trains on massive datasets using gradient descent. The result is a set of weights—billions of parameters—encoding statistical structure of language and knowledge. This learning: Is slow and expensive Persists across restarts Cannot easily be reversed Is vulnerable to interference if modified later Think of this as long-term biological memory. 2. Fine-Tuning (Days to Weeks) Fine-tuning modifies the weights further, but with narrower data. This includes: Instruction tuning (following directions) Alignment methods (Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO)) Domain adaptation Parameter-efficient methods like Low-Rank Adaptation (LoRA) This is still weight-based learning. It persists across restarts. It risks catastrophic forgetting. It modifies the brain itself. 3. Memory-Based Learning (Seconds to Minutes) This is where many modern systems shift. Instead of changing weights, they store information externally: RAG (Retrieval-Augmented Generation) CAG (Cache-Augmented Generation) Vector databases Engram-style memory modules The model retrieves relevant memory per query. The brain stays stable. The notebook grows. This learning: Persists across restarts Survives model upgrades Does not cause forgetting Is fast 4. In-Context Learning (Milliseconds) This is temporary reasoning scaffolding. Information exists only in the prompt window. It: Does not update weights Does not persist across sessions Is powerful but fragile Suffers from context rot This is working memory. Why This Matters Most discussions collapse all of this into “the model learned.” But: Updating weights risks forgetting Updating memory does not Updating prompts does not persist Updating adapters can be modular and reversible Continuous learning systems must coordinate all four. Persistence Comparison Mechanism Persists Across Chat? Persists Across Restart? Persists Across Model Change? Pretraining Yes Yes No Fine-tune Yes Yes No LoRA Yes Yes Usually Distillation Yes Yes No ICL No No No RAG Yes Yes Yes Engram Yes Yes Yes CAG Yes Yes Yes That last column is subtle but powerful for agents. References Concept Paper LoRA LoRA: Low-Rank Adaptation of Large Language Models (Hu et al. 2021) RAG Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (Lewis et al. 2020) ICL What Can Transformers Learn In-Context? (Garg et al. 2022) Engram Engram: Conditional Memory via Scalable Lookup (DeepSeek 2025) DPO Direct Preference Optimization (Rafailov et al. 2023) Coming Next In Part 2, we’ll examine the two fundamental failure modes that arise from confusing these layers: catastrophic forgetting and context rot. Learning happens in layers of permanence." />
<link rel="canonical" href="https://software-wrighter-lab.github.io/2026/02/24/how-ai-learns-part1-time-scales/" />
<meta property="og:url" content="https://software-wrighter-lab.github.io/2026/02/24/how-ai-learns-part1-time-scales/" />
<meta property="og:site_name" content="Software Wrighter Lab Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-02-24T08:00:00-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How AI Learns Part 1: The Many Meanings of Learning" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Software Wrighter"},"dateModified":"2026-02-24T08:00:00-08:00","datePublished":"2026-02-24T08:00:00-08:00","description":"When people say, “AI learned something,” they usually mean one of at least four very different things. Large Language Models (LLMs) do not learn in one single way. They learn at different time scales, in different locations, and with very different consequences. To understand modern AI systems—especially agents—we need to separate these layers. Resource Link Related ICL Revisited | RLM | Engram Four Time Scales of Learning Learning happens at different layers with different persistence and speed. 1. Pretraining (Years) This is the foundation. The model trains on massive datasets using gradient descent. The result is a set of weights—billions of parameters—encoding statistical structure of language and knowledge. This learning: Is slow and expensive Persists across restarts Cannot easily be reversed Is vulnerable to interference if modified later Think of this as long-term biological memory. 2. Fine-Tuning (Days to Weeks) Fine-tuning modifies the weights further, but with narrower data. This includes: Instruction tuning (following directions) Alignment methods (Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO)) Domain adaptation Parameter-efficient methods like Low-Rank Adaptation (LoRA) This is still weight-based learning. It persists across restarts. It risks catastrophic forgetting. It modifies the brain itself. 3. Memory-Based Learning (Seconds to Minutes) This is where many modern systems shift. Instead of changing weights, they store information externally: RAG (Retrieval-Augmented Generation) CAG (Cache-Augmented Generation) Vector databases Engram-style memory modules The model retrieves relevant memory per query. The brain stays stable. The notebook grows. This learning: Persists across restarts Survives model upgrades Does not cause forgetting Is fast 4. In-Context Learning (Milliseconds) This is temporary reasoning scaffolding. Information exists only in the prompt window. It: Does not update weights Does not persist across sessions Is powerful but fragile Suffers from context rot This is working memory. Why This Matters Most discussions collapse all of this into “the model learned.” But: Updating weights risks forgetting Updating memory does not Updating prompts does not persist Updating adapters can be modular and reversible Continuous learning systems must coordinate all four. Persistence Comparison Mechanism Persists Across Chat? Persists Across Restart? Persists Across Model Change? Pretraining Yes Yes No Fine-tune Yes Yes No LoRA Yes Yes Usually Distillation Yes Yes No ICL No No No RAG Yes Yes Yes Engram Yes Yes Yes CAG Yes Yes Yes That last column is subtle but powerful for agents. References Concept Paper LoRA LoRA: Low-Rank Adaptation of Large Language Models (Hu et al. 2021) RAG Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (Lewis et al. 2020) ICL What Can Transformers Learn In-Context? (Garg et al. 2022) Engram Engram: Conditional Memory via Scalable Lookup (DeepSeek 2025) DPO Direct Preference Optimization (Rafailov et al. 2023) Coming Next In Part 2, we’ll examine the two fundamental failure modes that arise from confusing these layers: catastrophic forgetting and context rot. Learning happens in layers of permanence.","headline":"How AI Learns Part 1: The Many Meanings of Learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://software-wrighter-lab.github.io/2026/02/24/how-ai-learns-part1-time-scales/"},"url":"https://software-wrighter-lab.github.io/2026/02/24/how-ai-learns-part1-time-scales/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://software-wrighter-lab.github.io/feed.xml" title="Software Wrighter Lab Blog" /><!-- Theme toggle script - load early to prevent flash -->
  <script>
    (function() {
      var stored = localStorage.getItem('sw-lab-theme');
      var theme = stored;
      if (!theme) {
        theme = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
      }
      document.documentElement.setAttribute('data-theme', theme);
    })();
  </script>
  <!-- Font size - load early to prevent flash -->
  <script>
    (function() {
      var NEW_DEFAULT = 110;
      var OLD_DEFAULT = 150;
      var stored = localStorage.getItem('sw-lab-font-size');
      var ack = localStorage.getItem('sw-lab-prefs-ack');
      var size = stored ? parseInt(stored, 10) : null;

      // Migration: if on old default and not acknowledged, use new default
      if (size === OLD_DEFAULT && ack !== 'true') {
        size = NEW_DEFAULT;
      } else if (size === null) {
        size = NEW_DEFAULT;
      }

      // Apply to post content when DOM is ready
      document.addEventListener('DOMContentLoaded', function() {
        var pc = document.querySelector('.post-content');
        if (pc) pc.style.fontSize = size + '%';
        var pl = document.querySelector('.post-list');
        if (pl) pl.style.fontSize = size + '%';
      });
    })();
  </script>
  <script src="/assets/js/theme-toggle.js" defer></script>
  <script src="/assets/js/font-size.js" defer></script>
  <script src="/assets/js/preferences.js" defer></script>
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">
      <img src="/assets/images/site/logo.jpg" alt="Software Wrighter Lab Blog" class="site-logo">
      <span class="site-title-text">Software Wrighter Lab Blog</span>
    </a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/abstracts/">Abstracts</a><a class="page-link" href="/index-all/">Index</a><a class="page-link" href="/series/">Series</a><a class="page-link" href="/tags/">Tags</a><a class="page-link" href="/categories/">Categories</a><a class="page-link" href="/search/">Search</a><div class="font-size-controls">
  <button class="font-size-btn" id="font-decrease" title="Decrease font size" aria-label="Decrease font size">A-</button>
  <button class="font-size-btn" id="font-reset" title="Reset font size" aria-label="Reset font size">A</button>
  <button class="font-size-btn" id="font-increase" title="Increase font size" aria-label="Increase font size">A+</button>
</div>
<button class="theme-toggle" aria-label="Switch theme" title="Switch theme">
  <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
  </svg>
  <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
    <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
  </svg>
</button>
</div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How AI Learns Part 1: The Many Meanings of Learning</h1><p class="post-meta">February 24, 2026 &bull; Software Wrighter</p>
<p class="post-reading-info"><em><span class="post-word-count">592 words</span> &bull; <span class="post-read-time">3 min read</span></em> &bull; <span class="abstract-toggle" onclick="this.classList.toggle('open'); this.parentElement.nextElementSibling.classList.toggle('open')">Abstract</span></p><div class="post-meta-abstract">When people say 'AI learned something,' they usually mean one of four very different things. Understanding these time scales---from milliseconds to years---is essential for building AI systems that improve safely over time.</div><div class="post-taxonomies"><span class="post-categories"><a href="/categories/#machine-learning" class="category">machine-learning</a><a href="/categories/#ai-agents" class="category">ai-agents</a></span><span class="post-tags"><a href="/tags/#llm" class="tag">llm</a><a href="/tags/#learning" class="tag">learning</a><a href="/tags/#pretraining" class="tag">pretraining</a><a href="/tags/#fine-tuning" class="tag">fine-tuning</a><a href="/tags/#rag" class="tag">rag</a><a href="/tags/#in-context-learning" class="tag">in-context-learning</a><a href="/tags/#continuous-learning" class="tag">continuous-learning</a></span></div></header><nav class="toc" data-toc-id="default">
  <h4>Contents</h4>
  <ul class="toc-list"></ul>
</nav>

<style>
/* Post content flows around floated TOC */
.post-content {
  overflow: hidden;
}

.toc {
  background: #fffde7;
  border-radius: 8px;
  padding: 1rem 1.5rem;
  margin: 0 1.5rem 1rem 0;
  float: left;
  max-width: 280px;
}

[data-theme="dark"] .toc {
  background: #3d3a00;
}

@media (prefers-color-scheme: dark) {
  :root:not([data-theme="light"]) .toc {
    background: #3d3a00;
  }
}

.toc h4 {
  margin: 0 0 0.75rem 0;
  font-size: 1rem;
}

.toc ul {
  margin: 0;
  padding-left: 1.25rem;
  list-style-type: disc;
}

.toc li {
  margin: 0.25rem 0;
}

.toc li.toc-h3 {
  margin-left: 1rem;
  font-size: 0.95em;
}

.toc a {
  text-decoration: none;
}

.toc a:hover {
  text-decoration: underline;
}


@media (max-width: 600px) {
  .toc {
    float: none;
    max-width: 100%;
    margin: 0 0 1.5rem 0;
  }
}

/* References section that floats alongside TOC */
.references-float {
  overflow: hidden; /* contain floated content */
}

.references-float h2 {
  margin-top: 0;
  font-size: 1.25rem;
}

.references-float table {
  font-size: 0.9em;
  width: 100%;
}

.references-float td, .references-float th {
  padding: 0.4rem 0.6rem;
  vertical-align: top;
}

.references-float td:first-child {
  white-space: nowrap;
  font-weight: bold;
  width: 1%;
}

@media (max-width: 600px) {
  .references-float table {
    font-size: 0.85em;
  }
}
</style>

<script>
(function() {
  // Run after DOM is ready
  function initTOC() {
    document.querySelectorAll('.toc').forEach(function(toc) {
      if (toc.dataset.initialized) return;
      toc.dataset.initialized = 'true';

      const tocList = toc.querySelector('.toc-list');
      if (!tocList) return;

      // Find the associated post-content (next sibling or parent's post-content)
      let article = toc.nextElementSibling;
      while (article && !article.classList.contains('post-content')) {
        article = article.nextElementSibling;
      }
      // Fallback: look for .post-content in the document (single post page)
      if (!article) {
        article = document.querySelector('.post-content');
      }

      if (!article) {
        toc.style.display = 'none';
        return;
      }

      const headings = article.querySelectorAll('h2, h3');

      if (headings.length < 3) {
        toc.style.display = 'none';
        return;
      }

      const tocId = toc.dataset.tocId || Math.random().toString(36).substr(2, 9);

      headings.forEach(function(heading, index) {
        // Add unique ID if missing
        if (!heading.id) {
          heading.id = 'toc-' + tocId + '-heading-' + index;
        }

        const li = document.createElement('li');
        li.className = 'toc-' + heading.tagName.toLowerCase();

        const a = document.createElement('a');
        a.href = '#' + heading.id;
        a.textContent = heading.textContent;

        li.appendChild(a);
        tocList.appendChild(li);
      });
    });
  }

  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', initTOC);
  } else {
    initTOC();
  }
})();
</script>
<div class="post-content e-content" itemprop="articleBody">
    <p><img src="/assets/images/posts/block-lamp-post.png" class="post-marker" alt="" /></p>

<p>When people say, “AI learned something,” they usually mean one of at least four very different things.</p>

<p>Large Language Models (LLMs) do not learn in one single way. They learn at different time scales, in different locations, and with very different consequences. To understand modern AI systems—especially agents—we need to separate these layers.</p>

<div class="resource-box">

  <table>
    <thead>
      <tr>
        <th>Resource</th>
        <th>Link</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Related</strong></td>
        <td><a href="/2026/02/22/icl-revisited-from-mystery-to-engineering/">ICL Revisited</a> | <a href="/2026/02/13/rlm-recursive-language-models/">RLM</a> | <a href="/2026/02/02/deepseek-papers-part2-engram/">Engram</a></td>
      </tr>
    </tbody>
  </table>

</div>

<h2 id="four-time-scales-of-learning">Four Time Scales of Learning</h2>

<figure>
<img src="/assets/images/posts/learning-time-scales.svg" alt="Concentric rings showing four time scales of learning: core weights, adapters, external memory, and prompt/context" style="max-width: 600px; margin: 0 auto; display: block;" />
<figcaption style="text-align: center; font-style: italic; margin-top: 0.5em;">Learning happens at different layers with different persistence and speed.</figcaption>
</figure>

<h3 id="1-pretraining-years">1. Pretraining (Years)</h3>

<p>This is the foundation.</p>

<p>The model trains on massive datasets using gradient descent. The result is a set of weights—billions of parameters—encoding statistical structure of language and knowledge.</p>

<p>This learning:</p>
<ul>
  <li>Is slow and expensive</li>
  <li>Persists across restarts</li>
  <li>Cannot easily be reversed</li>
  <li>Is vulnerable to interference if modified later</li>
</ul>

<p>Think of this as <strong>long-term biological memory</strong>.</p>

<h3 id="2-fine-tuning-days-to-weeks">2. Fine-Tuning (Days to Weeks)</h3>

<p>Fine-tuning modifies the weights further, but with narrower data.</p>

<p>This includes:</p>
<ul>
  <li><strong>Instruction tuning</strong> (following directions)</li>
  <li><strong>Alignment methods</strong> (Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO))</li>
  <li><strong>Domain adaptation</strong></li>
  <li><strong>Parameter-efficient methods</strong> like Low-Rank Adaptation (LoRA)</li>
</ul>

<p>This is still weight-based learning.</p>

<p>It persists across restarts. It risks <strong>catastrophic forgetting</strong>. It modifies the brain itself.</p>

<h3 id="3-memory-based-learning-seconds-to-minutes">3. Memory-Based Learning (Seconds to Minutes)</h3>

<p>This is where many modern systems shift.</p>

<p>Instead of changing weights, they store information externally:</p>
<ul>
  <li><strong>RAG</strong> (Retrieval-Augmented Generation)</li>
  <li><strong>CAG</strong> (Cache-Augmented Generation)</li>
  <li><strong>Vector databases</strong></li>
  <li><strong>Engram-style memory modules</strong></li>
</ul>

<p>The model retrieves relevant memory per query.</p>

<p><strong>The brain stays stable. The notebook grows.</strong></p>

<p>This learning:</p>
<ul>
  <li>Persists across restarts</li>
  <li>Survives model upgrades</li>
  <li>Does not cause forgetting</li>
  <li>Is fast</li>
</ul>

<h3 id="4-in-context-learning-milliseconds">4. In-Context Learning (Milliseconds)</h3>

<p>This is temporary reasoning scaffolding.</p>

<p>Information exists only in the prompt window.</p>

<p>It:</p>
<ul>
  <li>Does not update weights</li>
  <li>Does not persist across sessions</li>
  <li>Is powerful but fragile</li>
  <li>Suffers from <strong>context rot</strong></li>
</ul>

<p>This is <strong>working memory</strong>.</p>

<h2 id="why-this-matters">Why This Matters</h2>

<p>Most discussions collapse all of this into “the model learned.”</p>

<p>But:</p>
<ul>
  <li><strong>Updating weights</strong> risks forgetting</li>
  <li><strong>Updating memory</strong> does not</li>
  <li><strong>Updating prompts</strong> does not persist</li>
  <li><strong>Updating adapters</strong> can be modular and reversible</li>
</ul>

<p>Continuous learning systems must coordinate all four.</p>

<h2 id="persistence-comparison">Persistence Comparison</h2>

<table>
  <thead>
    <tr>
      <th>Mechanism</th>
      <th>Persists Across Chat?</th>
      <th>Persists Across Restart?</th>
      <th>Persists Across Model Change?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pretraining</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Fine-tune</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <td>LoRA</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>Usually</td>
    </tr>
    <tr>
      <td>Distillation</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <td>ICL</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>RAG</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Engram</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>CAG</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>

<p>That last column is subtle but powerful for agents.</p>

<h2 id="references">References</h2>

<table>
  <thead>
    <tr>
      <th>Concept</th>
      <th>Paper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>LoRA</td>
      <td><a href="https://arxiv.org/abs/2106.09685">LoRA: Low-Rank Adaptation of Large Language Models</a> (Hu et al. 2021)</td>
    </tr>
    <tr>
      <td>RAG</td>
      <td><a href="https://arxiv.org/abs/2005.11401">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a> (Lewis et al. 2020)</td>
    </tr>
    <tr>
      <td>ICL</td>
      <td><a href="https://arxiv.org/abs/2208.01066">What Can Transformers Learn In-Context?</a> (Garg et al. 2022)</td>
    </tr>
    <tr>
      <td>Engram</td>
      <td><a href="https://arxiv.org/abs/2501.09824">Engram: Conditional Memory via Scalable Lookup</a> (DeepSeek 2025)</td>
    </tr>
    <tr>
      <td>DPO</td>
      <td><a href="https://arxiv.org/abs/2305.18290">Direct Preference Optimization</a> (Rafailov et al. 2023)</td>
    </tr>
  </tbody>
</table>

<h2 id="coming-next">Coming Next</h2>

<p>In Part 2, we’ll examine the two fundamental failure modes that arise from confusing these layers: <strong>catastrophic forgetting</strong> and <strong>context rot</strong>.</p>

<hr />

<p><em>Learning happens in layers of permanence.</em></p>

  </div><div class="series-nav">
    <p><em>Part 1 of the How AI Learns series. <a href="/series/#how-ai-learns">View all parts</a></em></p>
  </div><img src="/assets/images/site/post-separator.png" class="post-separator" alt=""><a class="u-url" href="/2026/02/24/how-ai-learns-part1-time-scales/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Software Wrighter Lab Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Mike Wright</li><li><a class="u-email" href="mailto:"></a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/softwarewrighter"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">softwarewrighter</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>AI coding agents, systems programming, and practical machine learning</p>
      </div>
    </div>

    <div class="footer-copyright">
      <p>Copyright &copy; 2026 Michael A. Wright</p>
    </div>

  </div>

  <button id="scroll-to-top" aria-label="Scroll to top" title="Scroll to top">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <polyline points="18 15 12 9 6 15"></polyline>
    </svg>
  </button>

  <style>
  #scroll-to-top {
    position: fixed;
    bottom: 2rem;
    right: 2rem;
    width: 44px;
    height: 44px;
    border-radius: 50%;
    border: none;
    background: var(--brand-color, #2a7ae2);
    color: white;
    cursor: pointer;
    opacity: 0;
    visibility: hidden;
    transition: opacity 0.3s, visibility 0.3s, transform 0.2s;
    z-index: 1000;
    display: flex;
    align-items: center;
    justify-content: center;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.2);
  }

  #scroll-to-top:hover {
    transform: scale(1.1);
  }

  #scroll-to-top.visible {
    opacity: 1;
    visibility: visible;
  }

  #scroll-to-top svg {
    width: 24px;
    height: 24px;
  }
  </style>

  <script>
  (function() {
    const btn = document.getElementById('scroll-to-top');
    if (!btn) return;

    window.addEventListener('scroll', function() {
      if (window.scrollY > 300) {
        btn.classList.add('visible');
      } else {
        btn.classList.remove('visible');
      }
    });

    btn.addEventListener('click', function() {
      window.scrollTo({ top: 0, behavior: 'smooth' });
    });
  })();
  </script>

</footer>
</body>

</html>
